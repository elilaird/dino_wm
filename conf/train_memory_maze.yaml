defaults:
  - _self_
  - env: memory_maze_3x7
  - encoder: dino 
  - action_encoder: discrete
  - proprio_encoder: memmaze
  - decoder: vqvae
  - predictor: vit
  - model: base

dry_run: False
debug: False 

# base path to save model outputs. Checkpoints will be saved to ${ckpt_base_path}/outputs.
ckpt_base_path: /projects/coreyc/coreyc_mp_jepa/graph_world_models/ejlaird/dino_wm/checkpoints # put absolute path here

hydra:
  run:
    dir: ${ckpt_base_path}/outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${ckpt_base_path}/outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}

training:
  seed: 0
  epochs: 100
  batch_size: 512 # gpu_batch_size
  save_every_x_epoch: 10 
  reconstruct_every_x_batch: 500
  num_reconstruct_samples: 6
  encoder_lr: 1e-6
  decoder_lr: 3e-4
  predictor_lr: 1e-4
  action_encoder_lr: 5e-4
  max_grad_norm: 0.5
  # Cosine LR scheduler with warm restarts, decay, and warmup
  use_scheduler: True
  T_0: 10  # Number of steps for the first restart
  T_mult: 2  # A factor increases T_i after a restart
  eta_min_ratio: 0.01  # minimum LR as ratio of initial LR
  decay_factor: 0.9  # Factor to decay peak LR at each restart
  warmup_percent: 0.05 # warmup percentage of total steps

decoder_loss_type: smooth_l1

full_sequence: False
img_size: 64 
frameskip: 1
concat_dim: 1


# action encoder
action_emb_dim: 12
num_action_repeat: 1
normalize_action: False

# proprio encoder
proprio_emb_dim: 12 
num_proprio_repeat: 1

overlap_size: 0
num_frames: 100
num_hist: 9
num_pred: 1 
has_predictor: True # set this to False for only training a decoder
has_decoder: True # set this to False for only training a predictor

num_workers: 5
