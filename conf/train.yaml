defaults:
  - _self_
  - env: point_maze
  - encoder: dino 
  - action_encoder: proprio
  - proprio_encoder: proprio
  - decoder: vqvae
  - predictor: vit
  - model: base

dry_run: False
debug: False 

# base path to save model outputs. Checkpoints will be saved to ${ckpt_base_path}/outputs.
ckpt_base_path: /projects/coreyc/coreyc_mp_jepa/graph_world_models/ejlaird/dino_wm/checkpoints # put absolute path here

hydra:
  run:
    dir: ${ckpt_base_path}/outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${ckpt_base_path}/outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}

training:
  seed: 0
  epochs: 100
  batch_size: 256 # gpu_batch_size
  save_every_x_epoch: 10 
  reconstruct_every_x_batch: 500
  num_reconstruct_samples: 6
  encoder_lr: 1e-6
  decoder_lr: 3e-4
  predictor_lr: 5e-4
  action_encoder_lr: 5e-4
  encoder_weight_decay: 0.01
  decoder_weight_decay: 0.01
  predictor_weight_decay: 0.01
  action_encoder_weight_decay: 0.01
  max_grad_norm: 0.5
  # Cosine LR scheduler with warm restarts, decay, and warmup
  use_scheduler: True
  T_0: 2  # Number of steps for the first restart
  T_mult: 2  # A factor increases T_i after a restart
  eta_min_ratio: 0.1  # minimum LR as ratio of initial LR
  decay_factor: 0.9  # Factor to decay peak LR at each restart
  warmup_percent: 0.05 # warmup percentage of total steps

full_sequence: False
img_size: 224 # should be a multiple of 224
frameskip: 5
concat_dim: 1

normalize_action: True

# action encoder
action_emb_dim: 12
num_action_repeat: 1

# proprio encoder
proprio_emb_dim: 12 
num_proprio_repeat: 1

num_frames: null
num_hist: 4
num_pred: 1 # only supports 1
has_predictor: True # set this to False for only training a decoder
has_decoder: True # set this to False for only training a predictor

num_workers: 5
